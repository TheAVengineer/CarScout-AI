# Testing Quick Reference

## ğŸš€ Quick Start

```bash
# Run all tests
./scripts/run_tests.sh
```

## ğŸ“ Individual Tests

### 1. Setup Test
```bash
python scripts/test_setup.py
```
**Tests**: DB connection, seeds, migrations

### 2. Pipeline Test
```bash
python scripts/test_pipeline.py
```
**Tests**: Parse â†’ Normalize â†’ Dedupe â†’ Price â†’ AI â†’ Score

### 3. Alert Matcher Test
```bash
python scripts/test_alert_matcher.py
```
**Tests**: DSL parser, matching logic, rate limiting

### 4. Real Data Test
```bash
docker-compose exec worker scrapy crawl mobile_bg -a pages=1
```
**Tests**: Scraping, full pipeline with live data

## ğŸ” Monitoring

### Flower (Task Monitor)
```bash
open http://localhost:5555
```

### Database Queries
```bash
# Connect to DB
docker-compose exec db psql -U carscout_user -d carscout_db

# Count listings
SELECT COUNT(*) FROM listing_normalized;

# Check recent scores
SELECT ln.normalized_brand, ln.normalized_model, s.total_score, s.state
FROM score s
JOIN listing_normalized ln ON s.listing_id = ln.id
ORDER BY s.created_at DESC
LIMIT 10;

# Check duplicates
SELECT COUNT(*) FROM listing_normalized WHERE is_duplicate = true;
```

### Logs
```bash
# All logs
docker-compose logs -f

# Worker only
docker-compose logs -f worker

# API only
docker-compose logs -f api
```

## âš¡ Common Commands

### Services
```bash
# Start all
docker-compose up -d

# Stop all
docker-compose down

# Restart
docker-compose restart

# View status
docker-compose ps
```

### Database
```bash
# Run migrations
alembic upgrade head

# Seed data
python scripts/seed_database.py

# Reset database (âš ï¸ deletes all data)
docker-compose down -v
docker-compose up -d db
alembic upgrade head
python scripts/seed_database.py
```

### Scraping
```bash
# Mobile.bg (1 page)
docker-compose exec worker scrapy crawl mobile_bg -a pages=1

# Mobile.bg (10 pages)
docker-compose exec worker scrapy crawl mobile_bg -a pages=10

# All sources
docker-compose exec worker scrapy crawl mobile_bg -a pages=5
docker-compose exec worker scrapy crawl cars_bg -a pages=5
docker-compose exec worker scrapy crawl olx -a pages=5
```

## ğŸ› Debugging

### Check Task Status
```bash
# In Flower: http://localhost:5555
# Or via Python:
from workers.pipeline.celery_app import celery_app
celery_app.control.inspect().active()
```

### Check Redis Queue
```bash
docker-compose exec redis redis-cli
> LLEN celery
> KEYS *
```

### Check Celery Workers
```bash
docker-compose exec worker celery -A workers.pipeline.celery_app inspect active
docker-compose exec worker celery -A workers.pipeline.celery_app inspect stats
```

## ğŸ“Š Expected Results

### test_setup.py
```
âœ… Database Connection
âœ… Sources (3 found)
âœ… Plans (Free, Premium, Pro)
âœ… Brand/Model Mappings (17+ mappings)
âœ… User Creation
âœ… Normalization
âœ… Risk Evaluation
ğŸ‰ All tests passed!
```

### test_pipeline.py
```
âœ… Parse complete
âœ… Normalize complete
âœ… Dedupe complete
âš ï¸  Price complete (may fail if no comparables)
âœ… AI Risk complete
âœ… Score complete
ğŸ‰ Pipeline test PASSED!
```

### test_alert_matcher.py
```
âœ… DSL Parser (8 queries parsed)
âœ… Alert Matching (1 match found)
ğŸ‰ All alert matcher tests PASSED!
```

### Real Scraper
```
# In Flower, you should see:
scrape_listing â†’ SUCCESS
parse_listing â†’ SUCCESS
normalize_listing â†’ SUCCESS
deduplicate_listing â†’ SUCCESS
estimate_price â†’ SUCCESS (or FAILURE if no comparables)
classify_risk â†’ SUCCESS
calculate_score â†’ SUCCESS
post_to_channel â†’ SUCCESS (if approved)
match_alerts â†’ SUCCESS (if approved)
```

## â— Common Issues

### Import Errors
```bash
# Fix: Install dependencies
pip install -e ".[dev]"
```

### Database Connection Failed
```bash
# Fix: Start database
docker-compose up -d db
sleep 5
```

### Tasks Not Processing
```bash
# Fix: Restart workers
docker-compose restart worker beat
```

### No Comparables Found
```
# Expected: Need more data
# Fix: Scrape more pages
docker-compose exec worker scrapy crawl mobile_bg -a pages=10
```

## ğŸ“š More Info

See [TESTING.md](TESTING.md) for comprehensive guide.
